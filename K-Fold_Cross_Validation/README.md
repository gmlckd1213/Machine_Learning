# K-Fold Cross Validation

## Random Split의 문제
- 한두번 테스트로는 편차가 심할수 있음
- 검증용 데이터가 모델의 일반화된 성능을 추정
- 하지만 이것 역시 단 하나의 데이터 셋에 대한 추정일 뿐 단하나의 데이터 셋에서 얻은 성능으로는 정확도를 확신할 수 없음

## K-분할 교차 검증
- K-Fold Cross Validation
- 모든 데이터가 평가에 한 번, 학습에 k-1번 사용
- k개의 분할(Fold)에 대한 모든 성능 추정치 -> 평균과 표준편차 계산
- 단, k는 2 이상이 되어야 함(최소한 한 개씩의 학습용, 검증용 데이터가 필요 -> k는 정하기 나름

<img width="650" alt="image" src="https://user-images.githubusercontent.com/63540952/158012785-9ccf8595-2627-4281-b46e-5c7bf6972f65.png">

### 장점
- 모든 데이터를 학습과 평가에 사용할 수 있음
- 반복 학습과 평가를 통해 정확도를 향상시킬 수 있음
- 데이터가 부족해서 발생하는 과소적합 문제를 방지할 수 있음
- 평가에 사용되는 데이터의 편향을 막을 수 있음
- 좀 더 일반화된 모델을 만들 수 있음

### 단점
- 반복 횟수가 많아서 모델 학습과 평가에 많은 시간이 소요됨

<img width="663" alt="image" src="https://user-images.githubusercontent.com/63540952/158012980-1bde1189-5a33-4b4d-bb99-301ca42c0ad9.png">
- 테스트 데이터는 건들이지 않고 train데이터를 나눔
